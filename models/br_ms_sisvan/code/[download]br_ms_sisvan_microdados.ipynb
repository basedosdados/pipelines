{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sKdxybIH9KL1"
   },
   "source": [
    "_Recomendo utilizar de Drive para guarda os dados baixados e particionados._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bEKhIH0QYs4j"
   },
   "source": [
    "# Variaveis de caminho\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3C-gdEX0Ywwa"
   },
   "outputs": [],
   "source": [
    "year = 2015\n",
    "link_download = f\"https://s3.sa-east-1.amazonaws.com/ckan.saude.gov.br/SISVAN/estado_nutricional/sisvan_estado_nutricional_{year}.zip\"\n",
    "path_source_csv = f\"/content/input/{year}/sisvan_estado_nutricional_{year}.csv\"\n",
    "path_partitioned_folder = f\"/content/output/ano={year}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NOtIv8N2cplt"
   },
   "source": [
    "# Importaçoes e funçoes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AqjCFBm0cx7d"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import glob\n",
    "import io\n",
    "import os\n",
    "import re\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "\n",
    "def get_year(link: str) -> str:\n",
    "    year = re.search(\"[0-9]{4}\", link)\n",
    "    return year.group() if year else \"Falha\"\n",
    "\n",
    "\n",
    "def download_extract(link: str) -> None:\n",
    "    r = requests.get(link)\n",
    "    year = get_year(link)\n",
    "    z = ZipFile(io.BytesIO(r.content))\n",
    "    path = os.path.join(os.getcwd(), \"input\", year)\n",
    "    z.extractall(path)\n",
    "\n",
    "\n",
    "def create_folders(name_folders: str) -> None:\n",
    "    try:\n",
    "        os.makedirs(name_folders)\n",
    "\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "\n",
    "def extrair(path, path_output) -> None:\n",
    "    # loading the temp.zip and creating a zip object\n",
    "    with ZipFile(path, \"r\") as zObject:\n",
    "        # Extracting all the members of the zip\n",
    "        # into a specific location.\n",
    "        zObject.extractall(path=path_output)\n",
    "\n",
    "\n",
    "def csv_manager(path: str, row: dict, mode: str) -> None:\n",
    "    with open(path, mode, newline=\"\") as file:\n",
    "        # Create a CSV writer object\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        # Write the field names\n",
    "        if mode == \"w\":\n",
    "            writer.writerow(row.keys())\n",
    "        writer.writerow(row.values())\n",
    "\n",
    "\n",
    "def partition_dataset(path_source_dataset: str) -> None:\n",
    "    with open(path_source_dataset, \"r\", encoding=\"iso-8859-1\") as file:\n",
    "        reader = csv.DictReader(file, delimiter=\";\")\n",
    "        year = get_year(path_source_dataset)\n",
    "        for row in reader:\n",
    "            data = row[\"DT_ACOMPANHAMENTO\"]\n",
    "            mes = data.split(\"/\")[1]\n",
    "            path_output_csv = os.path.join(\n",
    "                os.getcwd(),\n",
    "                \"output\",\n",
    "                f\"ano={year}\",\n",
    "                f\"mes={mes}\",\n",
    "                f\"sigla_uf={row['SG_UF']}\",\n",
    "            )\n",
    "            file_csv = os.path.join(\n",
    "                path_output_csv,\n",
    "                f\"sisvan_nutricional_{row['SG_UF']}_{mes}_{year}.csv\",\n",
    "            )\n",
    "\n",
    "            if os.path.exists(file_csv):\n",
    "                csv_manager(file_csv, row, \"a\")\n",
    "            else:\n",
    "                create_folders(path_output_csv)\n",
    "                csv_manager(file_csv, row, \"w\")\n",
    "\n",
    "\n",
    "def verification_dataset_sum(sum_verify: int, row_sum_by_model: int) -> None:\n",
    "    if sum_verify == row_sum_by_model:\n",
    "        print(\n",
    "            f\"Processamento feito com sucesso!\\nValidação:\\n\"\n",
    "            f\"Soma linhas {sum_verify} | Soma verificadora por meses {row_sum_by_model}\"\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            f\"Processamento falho!\\nValidação:\\n\"\n",
    "            f\"Soma linhas {sum_verify} | Soma verificadora por meses {row_sum_by_model}\"\n",
    "        )\n",
    "        raise ValueError(\"Somas verificadoras não batem\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WjNSBrcVy04R"
   },
   "source": [
    "# Download e Particionar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G99BpLJIVKEB"
   },
   "source": [
    "## Download\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wn6kVXuGVK7X"
   },
   "outputs": [],
   "source": [
    "download_extract(link_download)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VFDsFNjwVLhT"
   },
   "source": [
    "## Particionar Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M60UvmPxel5l"
   },
   "outputs": [],
   "source": [
    "partition_dataset(path_source_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qBe3yFQCe0hs"
   },
   "source": [
    "## Validar Particionamento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lcPvV3yXfURy"
   },
   "outputs": [],
   "source": [
    "ufs = [\n",
    "    \"SP\",\n",
    "    \"RS\",\n",
    "    \"CE\",\n",
    "    \"MG\",\n",
    "    \"PE\",\n",
    "    \"MA\",\n",
    "    \"RJ\",\n",
    "    \"PI\",\n",
    "    \"AL\",\n",
    "    \"PR\",\n",
    "    \"BA\",\n",
    "    \"SC\",\n",
    "    \"RR\",\n",
    "    \"RN\",\n",
    "    \"MT\",\n",
    "    \"MS\",\n",
    "    \"AM\",\n",
    "    \"DF\",\n",
    "    \"PA\",\n",
    "    \"SE\",\n",
    "    \"AP\",\n",
    "    \"TO\",\n",
    "    \"ES\",\n",
    "    \"GO\",\n",
    "    \"PB\",\n",
    "    \"RO\",\n",
    "    \"AC\",\n",
    "]\n",
    "\n",
    "model_meses = {n: 0 for n in range(1, 13)}\n",
    "\n",
    "modelo_analise_particionado = {uf: model_meses.copy() for uf in ufs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cPp8ckmXiFM8"
   },
   "source": [
    "### Criar modelo de verificação Source Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i8td5iRpfmUV",
    "outputId": "1933a0e7-7787-42d7-b598-2e87e8e3db02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processamento feito com sucesso!\n",
      "Validação:\n",
      "Soma linhas 50544072 | Soma verificadora por meses 50544072\n"
     ]
    }
   ],
   "source": [
    "modelo_analise = {uf: model_meses.copy() for uf in ufs}\n",
    "\n",
    "# Specify the chunk size\n",
    "chunksize = 3000000\n",
    "\n",
    "# Open the CSV file in chunks\n",
    "row_sum_source_dataset = sum_verify_source_dataset = 0\n",
    "\n",
    "for chunk in pd.read_csv(\n",
    "    path_source_csv, chunksize=chunksize, encoding=\"iso-8859-1\", sep=\";\"\n",
    "):\n",
    "    # Process each chunk here\n",
    "    chunk[\"DT_ACOMPANHAMENTO\"] = pd.to_datetime(\n",
    "        chunk[\"DT_ACOMPANHAMENTO\"], format=\"%d/%m/%Y\"\n",
    "    )\n",
    "    chunk[\"ano\"] = chunk[\"DT_ACOMPANHAMENTO\"].dt.year\n",
    "    chunk[\"mes\"] = chunk[\"DT_ACOMPANHAMENTO\"].dt.month\n",
    "\n",
    "    for uf, meses in modelo_analise.items():\n",
    "        for mes in meses.keys():\n",
    "            modelo_analise[uf][mes] += len(\n",
    "                chunk[(chunk.SG_UF == uf) & (chunk.mes == mes)]\n",
    "            )\n",
    "    row_sum_source_dataset += len(chunk)\n",
    "\n",
    "for key, meses in modelo_analise.items():\n",
    "    total = sum(list(meses.values()))\n",
    "    sum_verify_source_dataset += total\n",
    "\n",
    "verification_dataset_sum(row_sum_source_dataset, sum_verify_source_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YlCdC1IaiTl9"
   },
   "source": [
    "### Criar modelo de verificação Partição\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u4-vyvdqij0g"
   },
   "outputs": [],
   "source": [
    "modelo_analise_particionado = {uf: model_meses.copy() for uf in ufs}\n",
    "\n",
    "row_sum_partition = sum_verify_partition = 0\n",
    "\n",
    "# Specify the path to the directory\n",
    "path = f\"{path_partitioned_folder}/**/*.csv\"\n",
    "\n",
    "# Use glob() to find all CSV files\n",
    "csv_files = glob.glob(path, recursive=True)\n",
    "\n",
    "for csv in csv_files:  # noqa: F402\n",
    "    fragment = csv.split(\"_\")\n",
    "    mes = int(fragment[4])\n",
    "    uf = fragment[3]\n",
    "    rows_part = len(pd.read_csv(csv))\n",
    "    modelo_analise_particionado[uf][mes] += rows_part\n",
    "    row_sum_partition += rows_part\n",
    "\n",
    "for key, meses in modelo_analise_particionado.items():\n",
    "    total = sum(list(meses.values()))\n",
    "    sum_verify_partition += total\n",
    "\n",
    "verification_dataset_sum(row_sum_partition, sum_verify_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5oSe0nTu5to"
   },
   "source": [
    "### Comparar Modelos de verificação\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RLIkLC_Au_93",
    "outputId": "a130412b-f29b-4114-8821-dd45abd237ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pasta Output pronto para upload!\n"
     ]
    }
   ],
   "source": [
    "erros = False\n",
    "for key, meses in modelo_analise_particionado.items():\n",
    "    for mes in range(1, 13):\n",
    "        total_particionado = modelo_analise_particionado[key][mes]\n",
    "        total_raw = modelo_analise[key][mes]\n",
    "        if total_particionado != total_raw:\n",
    "            print(\n",
    "                f\"Diferença em {key} no mês {mes}\\nParticionado: {total_particionado} Puro: {total_raw}\"\n",
    "            )\n",
    "            erros = True\n",
    "\n",
    "if erros:\n",
    "    print(\"Erro!\\nNão pronto para upload. Houve diferenças em algum mês\")\n",
    "    raise ValueError(\"Verifique as diferenças entre os modelos\")\n",
    "else:\n",
    "    print(\"Pasta Output pronto para upload!\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
