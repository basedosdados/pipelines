{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install basedosdados"
      ],
      "metadata": {
        "id": "cAuDOC62l1Yx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1e96abb6-85d2-4790-bf53-3d28abaf7822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting basedosdados\n",
            "  Downloading basedosdados-1.6.11-py3-none-any.whl (51 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/51.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Jinja2==3.0.3 (from basedosdados)\n",
            "  Downloading Jinja2-3.0.3-py3-none-any.whl (133 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/133.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.6/133.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ckanapi==4.6 (from basedosdados)\n",
            "  Downloading ckanapi-4.6.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting click==8.0.3 (from basedosdados)\n",
            "  Downloading click-8.0.3-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.5/97.5 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-cloud-bigquery==2.30.1 (from basedosdados)\n",
            "  Downloading google_cloud_bigquery-2.30.1-py2.py3-none-any.whl (203 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.0/204.0 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-cloud-bigquery-storage==1.1.0 (from basedosdados)\n",
            "  Downloading google_cloud_bigquery_storage-1.1.0-py2.py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.2/135.2 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-cloud-storage==1.42.3 (from basedosdados)\n",
            "  Downloading google_cloud_storage-1.42.3-py2.py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.0/106.0 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib-metadata<5.0.0,>=4.11.3 (from basedosdados)\n",
            "  Downloading importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\n",
            "Collecting loguru<0.7.0,>=0.6.0 (from basedosdados)\n",
            "  Downloading loguru-0.6.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<2.0.0,>=1.3.5 in /usr/local/lib/python3.10/dist-packages (from basedosdados) (1.5.3)\n",
            "Requirement already satisfied: pandas-gbq<0.18.0,>=0.17.4 in /usr/local/lib/python3.10/dist-packages (from basedosdados) (0.17.9)\n",
            "Collecting pandavro<2.0.0,>=1.6.0 (from basedosdados)\n",
            "  Downloading pandavro-1.7.2-py3-none-any.whl (8.8 kB)\n",
            "Collecting pyaml==20.4.0 (from basedosdados)\n",
            "  Downloading pyaml-20.4.0-py2.py3-none-any.whl (17 kB)\n",
            "Collecting pyarrow==6.0.0 (from basedosdados)\n",
            "  Downloading pyarrow-6.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.6/25.6 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ruamel.yaml==0.17.10 (from basedosdados)\n",
            "  Downloading ruamel.yaml-0.17.10-py3-none-any.whl (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.4/108.4 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting shapely<2.0.0,>=1.6.0 (from basedosdados)\n",
            "  Downloading Shapely-1.8.5.post1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: toml<0.11.0,>=0.10.2 in /usr/local/lib/python3.10/dist-packages (from basedosdados) (0.10.2)\n",
            "Collecting tomlkit==0.7.0 (from basedosdados)\n",
            "  Downloading tomlkit-0.7.0-py2.py3-none-any.whl (32 kB)\n",
            "Collecting tqdm==4.50.2 (from basedosdados)\n",
            "  Downloading tqdm-4.50.2-py2.py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.9/70.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from ckanapi==4.6->basedosdados) (67.7.2)\n",
            "Collecting docopt (from ckanapi==4.6->basedosdados)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ckanapi==4.6->basedosdados) (2.31.0)\n",
            "Requirement already satisfied: python-slugify>=1.0 in /usr/local/lib/python3.10/dist-packages (from ckanapi==4.6->basedosdados) (8.0.1)\n",
            "Requirement already satisfied: six<2.0,>=1.9 in /usr/local/lib/python3.10/dist-packages (from ckanapi==4.6->basedosdados) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.38.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery==2.30.1->basedosdados) (1.59.2)\n",
            "Requirement already satisfied: google-api-core[grpc]<3.0.0dev,>=1.29.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery==2.30.1->basedosdados) (2.11.1)\n",
            "Requirement already satisfied: proto-plus>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery==2.30.1->basedosdados) (1.22.3)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery==2.30.1->basedosdados) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery==2.30.1->basedosdados) (2.6.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery==2.30.1->basedosdados) (23.2)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery==2.30.1->basedosdados) (3.20.3)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery==2.30.1->basedosdados) (2.8.2)\n",
            "Collecting google-api-core[grpc]<3.0.0dev,>=1.29.0 (from google-cloud-bigquery==2.30.1->basedosdados)\n",
            "  Downloading google_api_core-1.34.0-py3-none-any.whl (120 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.2/120.2 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage==1.42.3->basedosdados) (2.17.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2==3.0.3->basedosdados) (2.1.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml==20.4.0->basedosdados) (6.0.1)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow==6.0.0->basedosdados) (1.23.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<5.0.0,>=4.11.3->basedosdados) (3.17.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0,>=1.3.5->basedosdados) (2023.3.post1)\n",
            "Requirement already satisfied: db-dtypes<2.0.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from pandas-gbq<0.18.0,>=0.17.4->basedosdados) (1.1.1)\n",
            "Requirement already satisfied: pydata-google-auth in /usr/local/lib/python3.10/dist-packages (from pandas-gbq<0.18.0,>=0.17.4->basedosdados) (1.8.2)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from pandas-gbq<0.18.0,>=0.17.4->basedosdados) (1.0.0)\n",
            "Collecting fastavro~=1.5.1 (from pandavro<2.0.0,>=1.6.0->basedosdados)\n",
            "  Downloading fastavro-1.5.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.29.0->google-cloud-bigquery==2.30.1->basedosdados) (1.61.0)\n",
            "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.29.0->google-cloud-bigquery==2.30.1->basedosdados) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage==1.42.3->basedosdados) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage==1.42.3->basedosdados) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage==1.42.3->basedosdados) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib>=0.0.1->pandas-gbq<0.18.0,>=0.17.4->basedosdados) (1.3.1)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery==2.30.1->basedosdados) (1.5.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify>=1.0->ckanapi==4.6->basedosdados) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ckanapi==4.6->basedosdados) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ckanapi==4.6->basedosdados) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ckanapi==4.6->basedosdados) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ckanapi==4.6->basedosdados) (2023.7.22)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage==1.42.3->basedosdados) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.0.1->pandas-gbq<0.18.0,>=0.17.4->basedosdados) (3.2.2)\n",
            "Building wheels for collected packages: ckanapi, docopt\n",
            "  Building wheel for ckanapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ckanapi: filename=ckanapi-4.6-py3-none-any.whl size=40677 sha256=70b82cf0e9ce1e91af8854acaa78128463d2433bc6b7bba4b339f571b53cbe0e\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/30/93/f9c2ebf4e93dc7b6abd5e376cdee291a6541ee504ac6ec4062\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=2ee89b77075275b6cf09f86686d375430528706fa7cb014cb6ae645a8302dfd5\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built ckanapi docopt\n",
            "Installing collected packages: docopt, tqdm, tomlkit, shapely, ruamel.yaml, pyarrow, pyaml, loguru, Jinja2, importlib-metadata, fastavro, click, ckanapi, pandavro, google-api-core, google-cloud-storage, google-cloud-bigquery-storage, google-cloud-bigquery, basedosdados\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.1\n",
            "    Uninstalling tqdm-4.66.1:\n",
            "      Successfully uninstalled tqdm-4.66.1\n",
            "  Attempting uninstall: shapely\n",
            "    Found existing installation: shapely 2.0.2\n",
            "    Uninstalling shapely-2.0.2:\n",
            "      Successfully uninstalled shapely-2.0.2\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 9.0.0\n",
            "    Uninstalling pyarrow-9.0.0:\n",
            "      Successfully uninstalled pyarrow-9.0.0\n",
            "  Attempting uninstall: Jinja2\n",
            "    Found existing installation: Jinja2 3.1.2\n",
            "    Uninstalling Jinja2-3.1.2:\n",
            "      Successfully uninstalled Jinja2-3.1.2\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 6.8.0\n",
            "    Uninstalling importlib-metadata-6.8.0:\n",
            "      Successfully uninstalled importlib-metadata-6.8.0\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.1.7\n",
            "    Uninstalling click-8.1.7:\n",
            "      Successfully uninstalled click-8.1.7\n",
            "  Attempting uninstall: google-api-core\n",
            "    Found existing installation: google-api-core 2.11.1\n",
            "    Uninstalling google-api-core-2.11.1:\n",
            "      Successfully uninstalled google-api-core-2.11.1\n",
            "  Attempting uninstall: google-cloud-storage\n",
            "    Found existing installation: google-cloud-storage 2.8.0\n",
            "    Uninstalling google-cloud-storage-2.8.0:\n",
            "      Successfully uninstalled google-cloud-storage-2.8.0\n",
            "  Attempting uninstall: google-cloud-bigquery-storage\n",
            "    Found existing installation: google-cloud-bigquery-storage 2.22.0\n",
            "    Uninstalling google-cloud-bigquery-storage-2.22.0:\n",
            "      Successfully uninstalled google-cloud-bigquery-storage-2.22.0\n",
            "  Attempting uninstall: google-cloud-bigquery\n",
            "    Found existing installation: google-cloud-bigquery 3.12.0\n",
            "    Uninstalling google-cloud-bigquery-3.12.0:\n",
            "      Successfully uninstalled google-cloud-bigquery-3.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "bigframes 0.13.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.10.0, but you have google-cloud-bigquery 2.30.1 which is incompatible.\n",
            "bigframes 0.13.0 requires google-cloud-storage>=2.0.0, but you have google-cloud-storage 1.42.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Jinja2-3.0.3 basedosdados-1.6.11 ckanapi-4.6 click-8.0.3 docopt-0.6.2 fastavro-1.5.4 google-api-core-1.34.0 google-cloud-bigquery-2.30.1 google-cloud-bigquery-storage-1.1.0 google-cloud-storage-1.42.3 importlib-metadata-4.13.0 loguru-0.6.0 pandavro-1.7.2 pyaml-20.4.0 pyarrow-6.0.0 ruamel.yaml-0.17.10 shapely-1.8.5.post1 tomlkit-0.7.0 tqdm-4.50.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IPLnj5ocyNm",
        "outputId": "fb03913b-3264-471b-9103-491a9cf32e8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import zipfile\n",
        "from zipfile import ZipFile\n",
        "import basedosdados as bd"
      ],
      "metadata": {
        "id": "ttcqngQqdXWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup inicial\n",
        "_necessário rodar apenas uma vez_\n",
        "\n",
        "* Download dos arquivos  \n",
        "* Criação das pastas de partição (ano) em output\n",
        "* Como os municípios são listados por nome, substituímos pelo id_municipio (ID Município - IBGE 7 Dígitos). Tal check cria a lista de todos os municípios que não dão match com a base de compatibilização extraída do diretório de município. Baseado nessa lista, faz-se o replace para um match 1:1"
      ],
      "metadata": {
        "id": "1fnt_SnhZNq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download dos dados originais\n",
        "for ano in [*range(2000, 2020)]:\n",
        "  if ano == 2018:\n",
        "    !wget --no-check-certificate -P /content/drive/MyDrive/basedosdados/br_inpe_sisam/input https://dataserver-coids.inpe.br/queimadas/queimadas/sisam/dados_sisam-{ano}.zip"
      ],
      "metadata": {
        "id": "7KCkQkVHJV8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cria pastas particionadas por ano\n",
        "for ano in [*range(2000, 2020)]:\n",
        "  directory = '/content/drive/MyDrive/basedosdados/br_inpe_sisam/output/ano={}'.format(ano)\n",
        "  if not os.path.exists(directory):\n",
        "    os.makedirs(directory)"
      ],
      "metadata": {
        "id": "Kl0G_5N7JZO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compatibilização da base entre nomes, siglas e ids\n",
        "query = '''\n",
        "SELECT\n",
        "  sigla_uf,\n",
        "  UPPER(nome_uf) AS uf_nome,\n",
        "  id_municipio,\n",
        "  UPPER(nome) AS municipio_nome\n",
        "FROM basedosdados.br_bd_diretorios_brasil.municipio\n",
        "'''\n",
        "\n",
        "comp = bd.read_sql(query, billing_project_id='input-dados')"
      ],
      "metadata": {
        "id": "GZ7gqHQXJpi4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce2f42e7-887f-463d-f6e1-caf7b0a2c758"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: 100%|██████████| 5570/5570 [00:00<00:00, 9604.05rows/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check de match para municipios\n",
        "unmatch_list = []\n",
        "\n",
        "for ano in [*range(2000, 2020)]:\n",
        "    file = '/content/drive/MyDrive/basedosdados/br_inpe_sisam/input/dados_sisam-{}.zip'.format(ano)\n",
        "    # descompacta o arquivo csv\n",
        "    with ZipFile(file) as z:\n",
        "      with z.open('task_9045.dados_sisam.{}.csv'.format(ano)) as f:\n",
        "        df = pd.read_csv(f)\n",
        "        # merge com diretorio\n",
        "        df = pd.merge(df, comp, how='left', on=['uf_nome', 'municipio_nome'], indicator=True)\n",
        "        # cria lista de municipios com typos\n",
        "        unmatch = df.query('_merge == \"left_only\"')['municipio_nome'].drop_duplicates().to_list()\n",
        "        # join entre anos\n",
        "        unmatch_list = unmatch_list + unmatch\n",
        "\n",
        "unmatch_list_unique = list(set(unmatch_list)) #lista conta com 28 municipios e typos para dados até 2019"
      ],
      "metadata": {
        "id": "9CWB-i0UCDsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tratamento"
      ],
      "metadata": {
        "id": "gLvxFJ9UZ629"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for ano in [*range(2000, 2020)]:\n",
        "  if ano == 2019:\n",
        "    file = '/content/drive/MyDrive/basedosdados/br_inpe_sisam/input/dados_sisam-{}.zip'.format(ano)\n",
        "    # descompacta o arquivo csv\n",
        "    with ZipFile(file) as z:\n",
        "      with z.open('task_9045.dados_sisam.{}.csv'.format(ano)) as f:\n",
        "        df = pd.read_csv(f)\n",
        "        df['municipio_nome'].replace({'ARAÇÁS':'ARAÇAS',\n",
        "                                      'ATÍLIO VIVACQUA':'ATILIO VIVACQUA',\n",
        "                                      'AUGUSTO SEVERO':'CAMPO GRANDE',\n",
        "                                      'BIRITIBA MIRIM':'BIRITIBA-MIRIM',\n",
        "                                      'FLORÍNEA':'FLORÍNIA',\n",
        "                                      'IGUARACY':'IGUARACI',\n",
        "                                      'ITAOCA':'ITAÓCA',\n",
        "                                      'ITAPAJÉ':'ITAPAGÉ',\n",
        "                                      'IUIU':'IUIÚ',\n",
        "                                      'JANUÁRIO CICCO':'BOA SAÚDE',\n",
        "                                      'LAURO MÜLLER':'LAURO MULLER',\n",
        "                                      'MUQUÉM DO SÃO FRANCISCO':'MUQUÉM DE SÃO FRANCISCO',\n",
        "                                      \"OLHO D'ÁGUA DO BORGES\":\"OLHO-D'ÁGUA DO BORGES\",\n",
        "                                      'PASSA VINTE':'PASSA-VINTE',\n",
        "                                      \"PINGO D'ÁGUA\":\"PINGO-D'ÁGUA\",\n",
        "                                      'POXORÉU':'POXORÉO',\n",
        "                                      'RESTINGA SÊCA':'RESTINGA SECA',\n",
        "                                      'SANTA IZABEL DO PARÁ':'SANTA ISABEL DO PARÁ',\n",
        "                                      'SÃO CRISTÓVÃO DO SUL':'SÃO CRISTOVÃO DO SUL',\n",
        "                                      'SÃO LUIZ DO NORTE':'SÃO LUÍZ DO NORTE',\n",
        "                                      'SÃO LUIZ DO PARAITINGA':'SÃO LUÍS DO PARAITINGA',\n",
        "                                      'SÃO VICENTE FÉRRER':'SÃO VICENTE FERRER',\n",
        "                                      'VESPASIANO CORRÊA':'VESPASIANO CORREA',\n",
        "                                      'WESTFÁLIA':'WESTFALIA'}, inplace=True)\n",
        "        df['municipio_nome'] = np.where((df['uf_nome'] == 'BAHIA') & (df['municipio_nome'] == 'SANTA TEREZINHA'), 'SANTA TERESINHA', df['municipio_nome'])\n",
        "        df['municipio_nome'] = np.where((df['uf_nome'] == 'PARAÍBA') & (df['municipio_nome'] == 'QUIXABA'), 'QUIXABÁ', df['municipio_nome'])\n",
        "        df = pd.merge(df, comp, how='left', on=['uf_nome', 'municipio_nome'], indicator=True)\n",
        "        df['sigla_uf'] = np.where((df['uf_nome'] == 'RIO GRANDE DO SUL') & (df['municipio_nome'] == 'LAGOA MIRIM'), 'RS', df['sigla_uf'])\n",
        "        df['sigla_uf'] = np.where((df['uf_nome'] == 'RIO GRANDE DO SUL') & (df['municipio_nome'] == 'LAGOA DOS PATOS'), 'RS', df['sigla_uf'])\n",
        "        df['id_municipio'] = np.where((df['uf_nome'] == 'RIO GRANDE DO SUL') & (df['municipio_nome'] == 'LAGOA MIRIM'), '4300001', df['id_municipio'])\n",
        "        df['id_municipio'] = np.where((df['uf_nome'] == 'RIO GRANDE DO SUL') & (df['municipio_nome'] == 'LAGOA DOS PATOS'), '4300002', df['id_municipio'])\n",
        "        df.rename(columns={'precipitacao_mmdia':'precipitacao_dia',\n",
        "                           'temperatura_c':'temperatura',\n",
        "                           'datahora':'data_hora',\n",
        "                           'umidade_relativa_percentual':'umidade_relativa',\n",
        "                           'vento_direcao_grau': 'vento_direcao',\n",
        "                           'vento_velocidade_ms':'vento_velocidade'}, inplace=True)\n",
        "        #df = df.query('_merge == \"both\"')\n",
        "        # df = df[['sigla_uf', 'id_municipio', 'data_hora', 'co_ppb', 'no2_ppb', 'o3_ppb', 'pm25_ugm3', 'so2_ugm3',\n",
        "        #          'precipitacao_dia', 'temperatura', 'umidade_relativa', 'vento_direcao', 'vento_velocidade']]\n",
        "        # df.to_csv('/content/drive/MyDrive/basedosdados/br_inpe_sisam/output/ano={}/microdados.csv'.format(ano), index=False, na_rep='')"
      ],
      "metadata": {
        "id": "BSL7hoyDgZCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df.dropna(subset='id_municipio')"
      ],
      "metadata": {
        "id": "MR7j62bklBUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eB-Mt-FknguK",
        "outputId": "cd27c2da-6097-4549-9933-a4c4f8836fa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8135120, 18)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbk94P37niCh",
        "outputId": "9ec05c6f-d780-40dc-f45f-d0f09d400f8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4067560, 18)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df.dropna(subset='id_municipio')\n",
        "print(df.shape)\n",
        "print(df2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SP3F_ZUen_qS",
        "outputId": "d87b2644-6b74-4d06-85a5-da0779d0ec8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8135120, 18)\n",
            "(8135120, 18)\n"
          ]
        }
      ]
    }
  ]
}
