"""datasus pop

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hsHGX_-FIHWqwR3nAcMZeTfnTBmzH7BW
"""

import ftplib
import io
import tempfile
import zipfile

import pandas as pd
from databasers_utils import TableArchitecture
from dbfread import DBF


def resgata_arquivo(ano):
    ftp = ftplib.FTP("ftp.datasus.gov.br")
    ftp.login()
    ftp.cwd("/dissemin/publicos/IBGE/POPSVS/")

    zip_filename = f"POPSBR{ano}.zip"
    zip_bytes = io.BytesIO()
    ftp.retrbinary(f"RETR {zip_filename}", zip_bytes.write)
    ftp.quit()

    #  lê o zip
    zip_bytes.seek(0)
    with zipfile.ZipFile(zip_bytes) as z:
        # pega o .dbf
        dbf_filename = next(
            name for name in z.namelist() if name.lower().endswith(".dbf")
        )

        # extrai o .dbf para arquivo temporário
        with tempfile.NamedTemporaryFile(
            delete=False, suffix=".dbf"
        ) as temp_dbf:
            temp_dbf.write(z.read(dbf_filename))
            temp_dbf_path = temp_dbf.name

    # lê .dbf usando dbfread
    dbf_data = DBF(
        temp_dbf_path, encoding="latin1"
    )  # tente 'cp1252' se necessário
    df = pd.DataFrame(iter(dbf_data))
    return df


def organiza_df(df):
    df.columns = ["id_municipio", "ano", "sexo", "idade", "populacao"]
    df = df[["ano", "id_municipio", "sexo", "idade", "populacao"]]
    df["sexo"] = (
        df["sexo"].astype("int").replace({1: "masculino", 2: "feminino"})
    )

    # Passo 1: Converter a idade para inteiro
    df["idade_int"] = df["idade"].astype(int)

    # Passo 2: Criar a faixa etária de 5 em 5 anos
    # Ex: 0-4, 5-9, ..., 75-79, 80+
    def faixa_etaria(idade):
        if idade >= 80:
            return "80-mais"
        else:
            faixa_inicio = (idade // 5) * 5
            faixa_fim = faixa_inicio + 4
            return f"{faixa_inicio}-{faixa_fim} anos"

    df["grupo_idade"] = df["idade_int"].apply(faixa_etaria)

    # Passo 3: Agrupar por cidade, sexo e faixa etária
    df_agrupado = df.groupby(
        ["ano", "id_municipio", "sexo", "grupo_idade"], as_index=False
    )["populacao"].sum()
    return df_agrupado


dados = pd.DataFrame()
anos = [
    "00",
    "01",
    "02",
    "03",
    "04",
    "05",
    "06",
    "07",
    "08",
    "09",
    "10",
    "11",
    "12",
    "13",
    "14",
    "15",
    "16",
    "17",
    "18",
    "19",
    "20",
    "21",
    "22",
    "23",
    "24",
]
for ano in anos:
    df = resgata_arquivo(ano)
    df_agrupado = organiza_df(df)
    dados = pd.concat([dados, df_agrupado])

dados["ano"] = dados.ano.astype("int")
dados["id_municipio"] = dados.id_municipio.astype("int")

# dados_canaa = dados[dados['id_municipio']==1502152]
# dados_canaa.to_csv('populacao_canaa.csv',index=False)

dados.to_csv("populacao_ms.csv", index=False)

# dados[dados['ano']>2020].to_csv('dados_desde_2021.csv',index=False)

# Particionamento
import os  # noqa: E402

base_path = "br_ms_populacao/output"

for ano, df_ano in df[df["ano"] >= 2022].groupby("ano"):
    pasta_ano = os.path.join(base_path, f"ano={ano}")
    os.makedirs(pasta_ano, exist_ok=True)

    nome_arquivo = f"br_ms_populacao_{ano}.csv"

    df_ano = df_ano.assign(
        ano=df_ano["ano"].astype("int64"),
        id_municipio=df_ano["id_municipio"].astype("string"),
        sexo=df_ano["sexo"].astype("string"),
        grupo_idade=df_ano["grupo_idade"].astype("string"),
        populacao=df_ano["populacao"].astype("int64"),
    )

    df_ano = df_ano[["id_municipio", "sexo", "grupo_idade", "populacao"]]

    df_ano.to_csv(os.path.join(pasta_ano, nome_arquivo), index=False, sep=",")

# Subir na BD

import basedosdados as bd  # noqa: E402

tb = bd.Table(dataset_id="br_ms_populacao", table_id="municipio")

tb.create(
    path="/br_ms_populacao/output",
    if_table_exists="raise",
    if_storage_data_exists="raise",
    source_format="csv",
)

# Criar arquivos DBT

arch = TableArchitecture(
    dataset_id="br_ms_populacao",
    tables={
        "municipio": "https://docs.google.com/spreadsheets/d/128nZetUtAXoE0PgIc0nb9rcBGqm5U_Wg/edit?usp=sharing&ouid=117308588429558922267&rtpof=true&sd=true",
    },
)

# Cria o yaml file
arch.create_yaml_file()

# Cria os arquivos sql
arch.create_sql_files()

# Atualiza o dbt_project.yml
arch.update_dbt_project()

# Faz o upload das colunas para o DJango
# Para essa etapa é necessário ter duas varíaveis de ambiente configurada
# BD_DJANGO_EMAIL="seuemail@basedosdados.org"
# BD_DJANGO_PASSWORD="password"
# arch.upload_columns()
