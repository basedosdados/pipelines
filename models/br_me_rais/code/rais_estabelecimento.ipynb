{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import basedosdados as bd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "\n",
    "def to_partitions(\n",
    "    data: pd.DataFrame,\n",
    "    partition_columns: List[str],\n",
    "    savepath: str,\n",
    "    file_type: str = \"csv\",\n",
    "):\n",
    "    \"\"\"Save data in to hive patitions schema, given a dataframe and a list of partition columns.\n",
    "    Args:\n",
    "        data (pandas.core.frame.DataFrame): Dataframe to be partitioned.\n",
    "        partition_columns (list): List of columns to be used as partitions.\n",
    "        savepath (str, pathlib.PosixPath): folder path to save the partitions.\n",
    "        file_type (str): default to csv. Accepts parquet.\n",
    "    Exemple:\n",
    "        data = {\n",
    "            \"ano\": [2020, 2021, 2020, 2021, 2020, 2021, 2021,2025],\n",
    "            \"mes\": [1, 2, 3, 4, 5, 6, 6,9],\n",
    "            \"sigla_uf\": [\"SP\", \"SP\", \"RJ\", \"RJ\", \"PR\", \"PR\", \"PR\",\"PR\"],\n",
    "            \"dado\": [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\",'h'],\n",
    "        }\n",
    "        to_partitions(\n",
    "            data=pd.DataFrame(data),\n",
    "            partition_columns=['ano','mes','sigla_uf'],\n",
    "            savepath='partitions/',\n",
    "        )\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(data, (pd.core.frame.DataFrame)):\n",
    "        savepath = Path(savepath)\n",
    "        # create unique combinations between partition columns\n",
    "        unique_combinations = (\n",
    "            data[partition_columns]\n",
    "            # .astype(str)\n",
    "            .drop_duplicates(subset=partition_columns)\n",
    "            .to_dict(orient=\"records\")\n",
    "        )\n",
    "\n",
    "        for filter_combination in unique_combinations:\n",
    "            patitions_values = [\n",
    "                f\"{partition}={value}\"\n",
    "                for partition, value in filter_combination.items()\n",
    "            ]\n",
    "\n",
    "            # get filtered data\n",
    "            df_filter = data.loc[\n",
    "                data[filter_combination.keys()]\n",
    "                .isin(filter_combination.values())\n",
    "                .all(axis=1),\n",
    "                :,\n",
    "            ]\n",
    "            df_filter = df_filter.drop(columns=partition_columns)\n",
    "\n",
    "            # create folder tree\n",
    "            filter_save_path = Path(savepath / \"/\".join(patitions_values))\n",
    "            filter_save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            if file_type == \"csv\":\n",
    "                # append data to csv\n",
    "                file_filter_save_path = Path(filter_save_path) / \"data.csv\"\n",
    "                df_filter.to_csv(\n",
    "                    file_filter_save_path,\n",
    "                    sep=\",\",\n",
    "                    encoding=\"utf-8\",\n",
    "                    na_rep=\"\",\n",
    "                    index=False,\n",
    "                    mode=\"a\",\n",
    "                    header=not file_filter_save_path.exists(),\n",
    "                )\n",
    "            elif file_type == \"parquet\":\n",
    "                # append data to parquet\n",
    "                file_filter_save_path = Path(filter_save_path) / \"data.parquet\"\n",
    "                df_filter.to_parquet(\n",
    "                    file_filter_save_path, index=False, compression=\"gzip\"\n",
    "                )\n",
    "    else:\n",
    "        raise BaseException(\"Data need to be a pandas DataFrame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 5570/5570 [00:00<00:00, 6164.87rows/s]\n",
      "Downloading: 100%|██████████| 27/27 [00:00<00:00, 86.26rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "natureza\n",
      "subatividade_ibge\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    \"X:\\\\dados\\\\br_me_rais\\\\estabelecimento_2023\\\\RAIS_ESTAB_PUB.txt\",\n",
    "    encoding=\"latin1\",\n",
    "    sep=\";\",\n",
    "    dtype=str,\n",
    ")\n",
    "\n",
    "df.rename(\n",
    "    columns={\n",
    "        \"Bairros SP\": \"bairros_sp\",\n",
    "        \"Bairros Fortaleza\": \"bairros_fortaleza\",\n",
    "        \"Bairros RJ\": \"bairros_rj\",\n",
    "        \"CNAE 2.0 Classe\": \"cnae_2\",\n",
    "        \"CNAE 95 Classe\": \"cnae_1\",\n",
    "        \"Distritos SP\": \"distritos_sp\",\n",
    "        \"Qtd Vínculos CLT\": \"quantidade_vinculos_clt\",\n",
    "        \"Qtd Vínculos Ativos\": \"quantidade_vinculos_ativos\",\n",
    "        \"Qtd Vínculos Estatutários\": \"quantidade_vinculos_estatutarios\",\n",
    "        \"Ind Atividade Ano\": \"indicador_atividade_ano\",\n",
    "        \"Ind CEI Vinculado\": \"indicador_cei_vinculado\",\n",
    "        \"Ind Estab Participa PAT\": \"indicador_pat\",\n",
    "        \"Ind Rais Negativa\": \"indicador_rais_negativa\",\n",
    "        \"Ind Simples\": \"indicador_simples\",\n",
    "        \"Município\": \"municipio\",\n",
    "        \"Natureza Jurídica\": \"natureza_juridica\",\n",
    "        \"Regiões Adm DF\": \"regioes_administrativas_df\",\n",
    "        \"CNAE 2.0 Subclasse\": \"cnae_2_subclasse\",\n",
    "        \"Tamanho Estabelecimento\": \"tamanho\",\n",
    "        \"Tipo Estab\": \"tipo\",\n",
    "        \"UF\": \"uf\",\n",
    "        \"IBGE Subsetor\": \"subsetor_ibge\",\n",
    "        \"CEP Estab\": \"cep\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "df[\"ano\"] = 2023\n",
    "\n",
    "df[\"municipio\"] = df[\"municipio\"].astype(str)\n",
    "\n",
    "# Carregar os arquivos\n",
    "\n",
    "df_municipio = bd.read_sql(\n",
    "    \"SELECT id_municipio, id_municipio_6 FROM `basedosdados.br_bd_diretorios_brasil.municipio`\",\n",
    "    billing_project_id=\"basedosdados\",\n",
    "    reauth=False,\n",
    ")\n",
    "df_uf = bd.read_sql(\n",
    "    \"SELECT id_uf, sigla FROM `basedosdados.br_bd_diretorios_brasil.uf`\",\n",
    "    billing_project_id=\"basedosdados\",\n",
    "    reauth=False,\n",
    ")\n",
    "\n",
    "# Mescla com o arquivo de municípios\n",
    "df = pd.merge(\n",
    "    df,\n",
    "    df_municipio,\n",
    "    left_on=\"municipio\",\n",
    "    right_on=\"id_municipio_6\",\n",
    "    how=\"left\",\n",
    ")\n",
    "df.drop([\"id_municipio_6\", \"municipio\"], axis=1, inplace=True)\n",
    "\n",
    "# Gerar a sigla_uf\n",
    "\n",
    "# Mescla com o arquivo de UFs\n",
    "df[\"uf\"] = df[\"uf\"].astype(str)\n",
    "df = pd.merge(df, df_uf, left_on=\"uf\", right_on=\"id_uf\", how=\"left\")\n",
    "df = df.drop([\"id_uf\", \"uf\"], axis=1)\n",
    "df = df.rename(columns={\"sigla\": \"sigla_uf\"})\n",
    "\n",
    "\n",
    "# Substitui sigla_uf vazia por \"IGNORADO\"\n",
    "df[\"sigla_uf\"].replace(np.nan, \"IGNORADO\", inplace=True)\n",
    "\n",
    "# Padronização das variáveis e dados\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == \"str\":\n",
    "        df[col] = df[col].str.strip()\n",
    "        df[col].replace([\"{ñ\", \"{ñ class}\", \"{ñ c\"], \"\", inplace=True)\n",
    "\n",
    "# Lista de variáveis\n",
    "vars_list = [\n",
    "    \"ano\",\n",
    "    \"sigla_uf\",\n",
    "    \"id_municipio\",\n",
    "    \"quantidade_vinculos_ativos\",\n",
    "    \"quantidade_vinculos_clt\",\n",
    "    \"quantidade_vinculos_estatutarios\",\n",
    "    \"natureza\",\n",
    "    \"natureza_juridica\",\n",
    "    \"tamanho\",\n",
    "    \"tipo\",\n",
    "    \"indicador_cei_vinculado\",\n",
    "    \"indicador_pat\",\n",
    "    \"indicador_simples\",\n",
    "    \"indicador_rais_negativa\",\n",
    "    \"indicador_atividade_ano\",\n",
    "    \"cnae_1\",\n",
    "    \"cnae_2\",\n",
    "    \"cnae_2_subclasse\",\n",
    "    \"subsetor_ibge\",\n",
    "    \"subatividade_ibge\",\n",
    "    \"cep\",\n",
    "    \"bairros_sp\",\n",
    "    \"distritos_sp\",\n",
    "    \"bairros_fortaleza\",\n",
    "    \"bairros_rj\",\n",
    "    \"regioes_administrativas_df\",\n",
    "]\n",
    "\n",
    "# Gera as variáveis não confirmadas\n",
    "for var in vars_list:\n",
    "    if var not in df.columns:\n",
    "        print(var)\n",
    "        df[var] = \"\"\n",
    "\n",
    "# Limpeza adicional de variáveis\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == \"str\":\n",
    "        print(col)\n",
    "        df[col] = df[col].str.strip()\n",
    "        df[col].replace(\n",
    "            [\"{ñ\", \"{ñ class}\", \"{ñ c\", \"{ñ clas}\"], \"\", inplace=True\n",
    "        )\n",
    "\n",
    "# Limpeza para variáveis específicas\n",
    "for col in [\n",
    "    \"bairros_sp\",\n",
    "    \"distritos_sp\",\n",
    "    \"bairros_fortaleza\",\n",
    "    \"bairros_rj\",\n",
    "    \"distritos_sp\",\n",
    "    \"regioes_administrativas_df\",\n",
    "    \"cnae_2\",\n",
    "    \"cnae_2_subclasse\",\n",
    "    \"subsetor_ibge\",\n",
    "    \"subatividade_ibge\",\n",
    "]:\n",
    "    df[col].replace(\n",
    "        [\n",
    "            \"0000\",\n",
    "            \"00000\",\n",
    "            \"000000\",\n",
    "            \"0000000\",\n",
    "            \"0000-1\",\n",
    "            \"000-1\",\n",
    "            \"998\",\n",
    "            \"999\",\n",
    "            \"9999\",\n",
    "            \"9997\",\n",
    "            \"00\",\n",
    "            \"-1\",\n",
    "        ],\n",
    "        \"\",\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "# Limpeza de natureza_juridica e cep\n",
    "df[\"natureza_juridica\"].replace([\"9990\", \"9999\"], \"\", inplace=True)\n",
    "df[\"cep\"].replace(\"0\", \"\", inplace=True)\n",
    "\n",
    "# Ajuste na variável tipo\n",
    "df[\"tipo\"].replace([\"CNPJ\", \"Cnpj\", \"01\", \"1\"], \"1\", inplace=True)\n",
    "df[\"tipo\"].replace([\"CAEPF\", \"Caepf\"], \"2\", inplace=True)\n",
    "df[\"tipo\"].replace(\n",
    "    [\"CEI\", \"Cei\", \"CEI/CNO\", \"Cei/Cno\", \"CNO\", \"Cno\", \"03\", \"3\"],\n",
    "    \"3\",\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# Converte colunas para numérico\n",
    "cols_to_numeric = [\n",
    "    \"id_municipio\",\n",
    "    \"quantidade_vinculos_ativos\",\n",
    "    \"quantidade_vinculos_clt\",\n",
    "    \"quantidade_vinculos_estatutarios\",\n",
    "    \"tamanho\",\n",
    "    \"indicador_cei_vinculado\",\n",
    "    \"indicador_pat\",\n",
    "    \"indicador_simples\",\n",
    "    \"indicador_rais_negativa\",\n",
    "    \"indicador_atividade_ano\",\n",
    "]\n",
    "df[cols_to_numeric] = df[cols_to_numeric].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# Reordena as colunas\n",
    "df = df[vars_list]\n",
    "\n",
    "to_partitions(\n",
    "    data=df,\n",
    "    partition_columns=[\"ano\", \"sigla_uf\"],\n",
    "    savepath=\"X:\\\\dados\\\\br_me_rais\\\\estabelecimento_2023\\\\estabelecimento\",\n",
    "    file_type=\"csv\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
