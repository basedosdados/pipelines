{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import basedosdados as bd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from os.path import join\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Tuple, Union\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "def to_partitions(\n",
    "    data: pd.DataFrame,\n",
    "    partition_columns: List[str],\n",
    "    savepath: str,\n",
    "    file_type: str = \"csv\",\n",
    "):\n",
    "    \"\"\"Save data in to hive patitions schema, given a dataframe and a list of partition columns.\n",
    "    Args:\n",
    "        data (pandas.core.frame.DataFrame): Dataframe to be partitioned.\n",
    "        partition_columns (list): List of columns to be used as partitions.\n",
    "        savepath (str, pathlib.PosixPath): folder path to save the partitions.\n",
    "        file_type (str): default to csv. Accepts parquet.\n",
    "    Exemple:\n",
    "        data = {\n",
    "            \"ano\": [2020, 2021, 2020, 2021, 2020, 2021, 2021,2025],\n",
    "            \"mes\": [1, 2, 3, 4, 5, 6, 6,9],\n",
    "            \"sigla_uf\": [\"SP\", \"SP\", \"RJ\", \"RJ\", \"PR\", \"PR\", \"PR\",\"PR\"],\n",
    "            \"dado\": [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\",'h'],\n",
    "        }\n",
    "        to_partitions(\n",
    "            data=pd.DataFrame(data),\n",
    "            partition_columns=['ano','mes','sigla_uf'],\n",
    "            savepath='partitions/',\n",
    "        )\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(data, (pd.core.frame.DataFrame)):\n",
    "        savepath = Path(savepath)\n",
    "        # create unique combinations between partition columns\n",
    "        unique_combinations = (\n",
    "            data[partition_columns]\n",
    "            # .astype(str)\n",
    "            .drop_duplicates(subset=partition_columns).to_dict(orient=\"records\")\n",
    "        )\n",
    "\n",
    "        for filter_combination in unique_combinations:\n",
    "            patitions_values = [\n",
    "                f\"{partition}={value}\"\n",
    "                for partition, value in filter_combination.items()\n",
    "            ]\n",
    "\n",
    "            # get filtered data\n",
    "            df_filter = data.loc[\n",
    "                data[filter_combination.keys()]\n",
    "                .isin(filter_combination.values())\n",
    "                .all(axis=1),\n",
    "                :,\n",
    "            ]\n",
    "            df_filter = df_filter.drop(columns=partition_columns)\n",
    "\n",
    "            # create folder tree\n",
    "            filter_save_path = Path(savepath / \"/\".join(patitions_values))\n",
    "            filter_save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            if file_type == \"csv\":\n",
    "                # append data to csv\n",
    "                file_filter_save_path = Path(filter_save_path) / \"data.csv\"\n",
    "                df_filter.to_csv(\n",
    "                    file_filter_save_path,\n",
    "                    sep=\",\",\n",
    "                    encoding=\"utf-8\",\n",
    "                    na_rep=\"\",\n",
    "                    index=False,\n",
    "                    mode=\"a\",\n",
    "                    header=not file_filter_save_path.exists(),\n",
    "                )\n",
    "            elif file_type == \"parquet\":\n",
    "                # append data to parquet\n",
    "                file_filter_save_path = Path(filter_save_path) / \"data.parquet\"\n",
    "                df_filter.to_parquet(\n",
    "                    file_filter_save_path, index=False, compression=\"gzip\"\n",
    "                )\n",
    "    else:\n",
    "        raise BaseException(\"Data need to be a pandas DataFrame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 5570/5570 [00:00<00:00, 6164.87rows/s]\n",
      "Downloading: 100%|██████████| 27/27 [00:00<00:00, 86.26rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "natureza\n",
      "subatividade_ibge\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    \"X:\\\\dados\\\\br_me_rais\\\\estabelecimento_2023\\\\RAIS_ESTAB_PUB.txt\",\n",
    "    encoding=\"latin1\",\n",
    "    sep=\";\",\n",
    "    dtype=str,\n",
    ")\n",
    "\n",
    "df.rename(columns={\n",
    "    'Bairros SP'                : 'bairros_sp',\n",
    "    'Bairros Fortaleza'         : 'bairros_fortaleza',\n",
    "    'Bairros RJ'                : 'bairros_rj',\n",
    "    'CNAE 2.0 Classe'           : 'cnae_2',\n",
    "    'CNAE 95 Classe'            : 'cnae_1',\n",
    "    'Distritos SP'              : 'distritos_sp',\n",
    "    'Qtd Vínculos CLT'          : 'quantidade_vinculos_clt',\n",
    "    'Qtd Vínculos Ativos'       : 'quantidade_vinculos_ativos',\n",
    "    'Qtd Vínculos Estatutários' : 'quantidade_vinculos_estatutarios',\n",
    "    'Ind Atividade Ano'         : 'indicador_atividade_ano',\n",
    "    'Ind CEI Vinculado'         : 'indicador_cei_vinculado',\n",
    "    'Ind Estab Participa PAT'   : 'indicador_pat',\n",
    "    'Ind Rais Negativa'         : 'indicador_rais_negativa',\n",
    "    'Ind Simples'               : 'indicador_simples',\n",
    "    'Município'                 : 'municipio',\n",
    "    'Natureza Jurídica'         : 'natureza_juridica',\n",
    "    'Regiões Adm DF'            : 'regioes_administrativas_df',\n",
    "    'CNAE 2.0 Subclasse'        : 'cnae_2_subclasse',\n",
    "    'Tamanho Estabelecimento'   : 'tamanho',\n",
    "    'Tipo Estab'                : 'tipo',\n",
    "    'UF'                        : 'uf',\n",
    "    'IBGE Subsetor'             : 'subsetor_ibge',\n",
    "    'CEP Estab'                 : 'cep',\n",
    "    }, inplace=True)\n",
    "\n",
    "df['ano'] = 2023\n",
    "\n",
    "df['municipio'] = df['municipio'].astype(str)\n",
    "\n",
    "# Carregar os arquivos\n",
    "\n",
    "df_municipio = bd.read_sql('SELECT id_municipio, id_municipio_6 FROM `basedosdados.br_bd_diretorios_brasil.municipio`', billing_project_id='basedosdados', reauth=False)\n",
    "df_uf = bd.read_sql('SELECT id_uf, sigla FROM `basedosdados.br_bd_diretorios_brasil.uf`', billing_project_id='basedosdados', reauth=False)\n",
    "\n",
    "# Mescla com o arquivo de municípios\n",
    "df = pd.merge(df, df_municipio, left_on='municipio', right_on='id_municipio_6', how='left')\n",
    "df.drop(['id_municipio_6', 'municipio'], axis=1, inplace=True)\n",
    "\n",
    "# Gerar a sigla_uf\n",
    "\n",
    "# Mescla com o arquivo de UFs\n",
    "df['uf'] = df['uf'].astype(str)\n",
    "df = pd.merge(df, df_uf, left_on='uf', right_on='id_uf', how='left')\n",
    "df = df.drop(['id_uf', 'uf'], axis=1)\n",
    "df = df.rename(columns={'sigla': 'sigla_uf'})\n",
    "\n",
    "\n",
    "# Substitui sigla_uf vazia por \"IGNORADO\"\n",
    "df['sigla_uf'].replace(np.nan, \"IGNORADO\", inplace=True)\n",
    "\n",
    "# Padronização das variáveis e dados\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'str':\n",
    "        df[col] = df[col].str.strip()\n",
    "        df[col].replace([\"{ñ\", \"{ñ class}\", \"{ñ c\"], \"\", inplace=True)\n",
    "\n",
    "# Lista de variáveis\n",
    "vars_list = [\n",
    "    'ano',\n",
    "    'sigla_uf',\n",
    "    'id_municipio',\n",
    "    'quantidade_vinculos_ativos',\n",
    "    'quantidade_vinculos_clt',\n",
    "    'quantidade_vinculos_estatutarios',\n",
    "    'natureza',\n",
    "    'natureza_juridica',\n",
    "    'tamanho',\n",
    "    'tipo',\n",
    "    'indicador_cei_vinculado',\n",
    "    'indicador_pat',\n",
    "    'indicador_simples',\n",
    "    'indicador_rais_negativa',\n",
    "    'indicador_atividade_ano',\n",
    "    'cnae_1',\n",
    "    'cnae_2',\n",
    "    'cnae_2_subclasse',\n",
    "    'subsetor_ibge',\n",
    "    'subatividade_ibge',\n",
    "    'cep',\n",
    "    'bairros_sp',\n",
    "    'distritos_sp',\n",
    "    'bairros_fortaleza',\n",
    "    'bairros_rj',\n",
    "    'regioes_administrativas_df'\n",
    "]\n",
    "\n",
    "# Gera as variáveis não confirmadas\n",
    "for var in vars_list:\n",
    "    if var not in df.columns:\n",
    "        print(var)\n",
    "        df[var] = \"\"\n",
    "\n",
    "# Limpeza adicional de variáveis\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'str':\n",
    "        print(col)\n",
    "        df[col] = df[col].str.strip()\n",
    "        df[col].replace([\"{ñ\", \"{ñ class}\", \"{ñ c\", \"{ñ clas}\"], \"\", inplace=True)\n",
    "\n",
    "# Limpeza para variáveis específicas\n",
    "for col in ['bairros_sp', 'distritos_sp', 'bairros_fortaleza', 'bairros_rj',  'distritos_sp', 'regioes_administrativas_df', 'cnae_2', 'cnae_2_subclasse', 'subsetor_ibge', 'subatividade_ibge']:\n",
    "    df[col].replace([\"0000\", \"00000\", \"000000\", \"0000000\", \"0000-1\", \"000-1\", \"998\", \"999\", \"9999\", \"9997\", \"00\", \"-1\"], \"\", inplace=True)\n",
    "\n",
    "# Limpeza de natureza_juridica e cep\n",
    "df['natureza_juridica'].replace([\"9990\", \"9999\"], \"\", inplace=True)\n",
    "df['cep'].replace(\"0\", \"\", inplace=True)\n",
    "\n",
    "# Ajuste na variável tipo\n",
    "df['tipo'].replace([\"CNPJ\", \"Cnpj\", \"01\", \"1\"], \"1\", inplace=True)\n",
    "df['tipo'].replace([\"CAEPF\", \"Caepf\"], \"2\", inplace=True)\n",
    "df['tipo'].replace([\"CEI\", \"Cei\", \"CEI/CNO\", \"Cei/Cno\", \"CNO\", \"Cno\", \"03\", \"3\"], \"3\", inplace=True)\n",
    "\n",
    "# Converte colunas para numérico\n",
    "cols_to_numeric = ['id_municipio', 'quantidade_vinculos_ativos', 'quantidade_vinculos_clt', 'quantidade_vinculos_estatutarios', 'tamanho', 'indicador_cei_vinculado', 'indicador_pat', 'indicador_simples', 'indicador_rais_negativa', 'indicador_atividade_ano']\n",
    "df[cols_to_numeric] = df[cols_to_numeric].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Reordena as colunas\n",
    "df = df[vars_list]\n",
    "\n",
    "to_partitions(\n",
    "    data=df,\n",
    "    partition_columns=[\"ano\", \"sigla_uf\"],\n",
    "    savepath=\"X:\\\\dados\\\\br_me_rais\\\\estabelecimento_2023\\\\estabelecimento\",\n",
    "    file_type=\"csv\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
