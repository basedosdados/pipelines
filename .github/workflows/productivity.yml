# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.

# GitHub recommends pinning actions to a commit SHA.
# To get a newer version, you will need to update the SHA.
# You can also reference a tag or branch, but the action may change without warning.

name: Weekly Team Sync
on:
  schedule:
    - cron: 0 8 * * 1

jobs:
  create_issue:
    name: Create team sync issue
    runs-on: ubuntu-latest
    permissions:
      issues: write
    steps:
      - name: Create team sync issue
        uses: imjohnbo/issue-bot@3d96848fb5e9a4a473bb81ae62b4b4866a56e93a
        with:
          assignees: "arthurfg, tricktx, gabrielle-carv"
          labels: "productivity"
          title: "Pipeline <dataset_id>"
          body: |
              **Metadados da base**

              1. Descrição: <descrição da base e suas tabelas>

              <!-- Para (2) e (3): veja como nomeamos nossos conjuntos e tabelas aqui https://basedosdados.github.io/mais/style_data/#nomea%C3%A7%C3%A3o-de-bases-e-tabelas -->

              2. Qual o nome do conjunto? `dataset_id`

              3. Qual o nome da(s) tabela(s)? `table_id`

              4. Fonte original dos dados
                  * Endereço: <url>
                  * Tem API? <sim> / <não>
                  * É grátis? <sim> / <não>
                  * Cobertura espacial: <area.slug>
                  * Cobertura temporal: de YYYY-MM-DD a YYYY-MM-DD
                  * Frequência de atualização: <year> / <semester> / <quarter> / <month> / <day> / <hour> / <minute> / <second>

              5. Raspagem
                  * Nível de dificuldade: <baixo> / <médio> / <alto>
                  * Existe código semi-pronto? <sim> / <não>
                  * Dificuldades de big data (alta frequência, alto volume)? <sim> / <não>

              **Tarefas** (seguindo os passos da documentação [aqui](https://basedosdados.github.io/mais/colab_data/))

              - [ ] Baixar a pasta template e os dados originais
              - [ ] Preencher as tabelas de arquitetura - Marcar a equipe de dados na issue avisando quando finalizar
              - [ ] Escrever código de captura e limpeza de dados
              - [ ] Organizar arquivos brutos, se necessário
              - [ ] Organizar arquivos auxiliares, se necessário
              - [ ] Criar tabela dicionário, se necessário
              - [ ] Subir tabelas no BigQuery
              - [ ] Fazer uma revisão seguindo o [nosso guia](https://github.com/basedosdados/.github/wiki/Dados#como-fazer-code-review)
              - [ ] Abrir o PR
              - [ ] Escrever a pipeline
          pinned: false
          close-previous: false
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
